{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 감정분석\n",
    "- 감정 또는 감성(sentiment)\n",
    "- 텍스트에 나타난 긍정/부정의 태도\n",
    "- 기계학습 방식과 사전 방식\n",
    "\n",
    "### 감정사전\n",
    "- 긍정 표현, 부정 표현의 사전\n",
    "- 해당 분야 전문가가 있으면 데이터 없이도 만들 수 있음\n",
    "- 기계학습으로도 개발 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화평\n",
    "\n",
    "- 네이버 영화에서 분석하고 싶은 영화 페이지로 들어감\n",
    "- 네티즌 별점 클릭\n",
    "- 페이지 번호 우클릭 후 주소 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=150689&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page={}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리뷰 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "\n",
    "# 리뷰와 별점을 모을 빈 리스트를 만든다\n",
    "reviews = []\n",
    "scores = []\n",
    "\n",
    "for page in range(1, 30):  # 1~29페이지까지 반복\n",
    "    res = requests.get(url.format(page))  # 각 페이지에 접속한다\n",
    "    root = lxml.html.fromstring(res.text)  # html을 처리한다\n",
    "\n",
    "    # 리뷰를 가져와 reviews에 추가한다\n",
    "    for review in root.cssselect('.score_reple p'):\n",
    "        reviews.append(review.text_content())\n",
    "\n",
    "    # 별점을 가져와 scores에 추가한다\n",
    "    for score in root.cssselect('.score_result .star_score em'):\n",
    "        scores.append(int(score.text_content()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'score': scores, \n",
    "    'review': reviews\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긍/부정 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = np.where(df['score'] > 5, 1, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "df.to_csv('movie_review.csv', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "df = pd.read_csv('movie_review.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글, 알파벳, 숫자 제외한 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_word(text):\n",
    "    \"\"\"한글, 알파벳, 숫자를 제외한 문자를 제거\"\"\"\n",
    "    return re.sub(r'[^가-힣A-z0-9]+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_non_word('Wow, 정말 1도 재미 없다!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WPM(Word Piece Model) 학습\n",
    " - 구글의 WPM에는 BPE(Byte Pair Encoding) 알고리즘\n",
    "    - 자연어 처리를 위한 주요 전처리 방법으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "import io\n",
    "\n",
    "with open('영화평BPE.txt', 'w', encoding='utf8') as outfile:\n",
    "    infile = io.StringIO(remove_non_word(' '.join(df['review'])))\n",
    "    learn_bpe(infile, outfile, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subword_nmt.apply_bpe import BPE\n",
    "\n",
    "with open('영화평BPE.txt', encoding='utf8') as f:\n",
    "    bpe = BPE(f, separator='~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TDM 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BoW(Bag of Words)란 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법\n",
    "<img src=\"TDM.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_wpm(text):\n",
    "    text = remove_non_word(text)\n",
    "    tokens = bpe.process_line(text)\n",
    "    tokens = tokens.split()\n",
    "    return [t for t in tokens\n",
    "            if (not t.endswith('~') and len(t) > 1) or len(t) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_wpm = CountVectorizer(max_features=1000, tokenizer=tokenizer_wpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm = cv_wpm.fit_transform(df['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰 빈도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.DataFrame({\n",
    "    'word': cv_wpm.get_feature_names(),\n",
    "    'n': tdm.sum(axis=0).flat\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.sort_values('n').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    tdm, df['sentiment'], test_size=.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "model = LogisticRegressionCV(random_state=1234)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_coef = pd.DataFrame({\n",
    "    'word': cv_wpm.get_feature_names(),\n",
    "    'coef': model.coef_.flat\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_coef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_coef.sort_values('coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_coef.sort_values('coef').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
