xml_node('.score_reple') %>%
xml_nodes('.star_score') %>%
xml_attr('href') -> so
read_xml(movie) %>%
xml_node('.score_reple') %>%
xml_nodes('.star_score')
read_xml(movie) %>%
xml_node('.score_reple') %>%
xml_nodes('.star_score')
base <- 'http://www.hanbit.co.kr/academy/books/new_book_list.html'
read_html(base) %>%
html_node('#category_books') %>%
html_nodes('a') %>%
html_attr('href') -> category_urls
category_urls
naver <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
# 가져오기
movie <- read_html(naver)
# 평점 가져오기
score <- html_nodes(movie, '.score_reple')%>% html_text() ;score
star <-  html_nodes(movie, '.star_score');star
# 지저분한거 지우기
score <- gsub("^\\n+|\\t+$", "", score)
star <- gsub("^\\s+|\\s+$", "", star)
read_html(naver) %>%
html_node('#score_reple') %>%
html_nodes('p') %>%
html_attr('href') -> score_urls
score_urls
base <- 'http://www.hanbit.co.kr/academy/books/new_book_list.html'
read_html(naver) %>%
html_node('#score_reple') %>%
html_nodes('p') %>%
html_attr('href') -> score_urls
score_urls
url_base <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
all.reviews <- c()
for(page in 1:20){
url <- paste(url_base,page,sep='',encoding="euc-kr")
for(page in 1:20){
url <- paste(url_base,page,sep='',encoding="euc-kr")
# read_html 함수를 사용하여 html 페이지를 htxt 변수에 저장
htxt <- read_html(url)
# html_nodes 함수를 사용하여 list_netizen class에 해당하는 부분을 table 변수에 저자
table <- html_nodes(htxt,'.list_netizen')
# html_nodes 함수를 사용하여 title class에 해당하는 부분을 content 변수에 저자
content <- html_nodes(table, '.title')
# html_text 함수를 사용하여 text 부분을 reviews 변수에 저장
reviews <- html_text(content)
if(length(reviews)==0){break}
all.reviews <- c(all.reviews, reviews)
print(page)
}
write.table(all.reviews, 'naver.txt')
url_base <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
all.reviews <- c()
for(page in 1:20){
url <- paste(url_base,page,sep='',encoding="euc-kr")
# read_html 함수를 사용하여 html 페이지를 htxt 변수에 저장
htxt <- read_html(url)
# html_nodes 함수를 사용하여 list_netizen class에 해당하는 부분을 table 변수에 저자
table <- html_nodes(htxt,'.list_netizen')
# html_nodes 함수를 사용하여 title class에 해당하는 부분을 content 변수에 저자
content <- html_nodes(table, '.title')
# html_text 함수를 사용하여 text 부분을 reviews 변수에 저장
reviews <- html_text(content)
if(length(reviews)==0){break}
all.reviews <- c(all.reviews, reviews)
print(page)
}
for(page in 1:20){
url <- paste(url_base,page,sep='',encoding="euc-kr")
# read_html 함수를 사용하여 html 페이지를 htxt 변수에 저장
htxt <- read_html(url)
# html_nodes 함수를 사용하여 list_netizen class에 해당하는 부분을 table 변수에 저자
table <- html_nodes(htxt,'.list_netizen')
# html_nodes 함수를 사용하여 title class에 해당하는 부분을 content 변수에 저자
content <- html_nodes(table, '.title')
# html_text 함수를 사용하여 text 부분을 reviews 변수에 저장
reviews <- html_text(content)
if(length(reviews)==0){break}
all.reviews <- c(all.reviews, reviews)
print(page)
}
write.table(all.reviews, 'naver.txt')
# user agent 정보 설정
header = httr::user_agent("Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36")
# 기본 url
base_url <- httr::GET('https://www.instagram.com/explore/tags/doll',header)
# 서버가 반응 했는지 알아보기
base_url$status_code
url_base <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
all.reviews <- c()
for(page in 1:20){
url <- paste(url_base,page,sep='',encoding="euc-kr")
# read_html 함수를 사용하여 html 페이지를 htxt 변수에 저장
htxt <- read_html(url)
# html_nodes 함수를 사용하여 list_netizen class에 해당하는 부분을 table 변수에 저자
table <- html_nodes(htxt,'.list_netizen')
# html_nodes 함수를 사용하여 title class에 해당하는 부분을 content 변수에 저자
content <- html_nodes(table, '.title')
# html_text 함수를 사용하여 text 부분을 reviews 변수에 저장
reviews <- html_text(content)
if(length(reviews)==0){break}
all.reviews <- c(all.reviews, reviews)
print(page)
}
write.table(all.reviews, 'naver.txt')
url_base <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
library(rvest)
library(dplyr)
library(stringr)
library(openxlsx)
url_base <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
all.reviews <- c()
for(page in 1:20){
url <- paste(url_base,page,sep='',encoding="euc-kr")
# read_html 함수를 사용하여 html 페이지를 htxt 변수에 저장
htxt <- read_html(url)
# html_nodes 함수를 사용하여 list_netizen class에 해당하는 부분을 table 변수에 저자
table <- html_nodes(htxt,'.list_netizen')
# html_nodes 함수를 사용하여 title class에 해당하는 부분을 content 변수에 저자
content <- html_nodes(table, '.title')
# html_text 함수를 사용하여 text 부분을 reviews 변수에 저장
reviews <- html_text(content)
if(length(reviews)==0){break}
all.reviews <- c(all.reviews, reviews)
print(page)
}
write.table(all.reviews, 'naver.txt')
for(page in 1:20){
url <- paste(url_base,page,sep='',encoding="euc-kr")
# read_html 함수를 사용하여 html 페이지를 htxt 변수에 저장
htxt <- read_html(url)
# html_nodes 함수를 사용하여 list_netizen class에 해당하는 부분을 table 변수에 저자
table <- html_nodes(htxt,'.list_netizen')
# html_nodes 함수를 사용하여 title class에 해당하는 부분을 content 변수에 저자
content <- html_nodes(table, '.title')
# html_text 함수를 사용하여 text 부분을 reviews 변수에 저장
reviews <- html_text(content)
if(length(reviews)==0){break}
all.reviews <- c(all.reviews, reviews)
print(page)
}
url_base <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
all.reviews <- c()
for(page in 1:20){
url <- paste(url_base,page,sep='',encoding="euc-kr")
# read_html 함수를 사용하여 html 페이지를 htxt 변수에 저장
htxt <- read_html(url)
# html_nodes 함수를 사용하여 list_netizen class에 해당하는 부분을 table 변수에 저자
table <- html_nodes(htxt,'.list_netizen')
# html_nodes 함수를 사용하여 title class에 해당하는 부분을 content 변수에 저자
content <- html_nodes(table, '.title')
# html_text 함수를 사용하여 text 부분을 reviews 변수에 저장
reviews <- html_text(content)
if(length(reviews)==0){break}
all.reviews <- c(all.reviews, reviews)
print(page)
}
naver <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
naver <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
base_url <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
base_url <- "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false"
page_url_base <- ste_sub(tmp, 1, -2)
html2 %>%
html_node('div.paging') %>%
html_node('a') %>%
html_attr('href') -> tmp
pages <- gsub(',','',pages)
html2 %>%
html_node('div.score_total') %>%
html_nodes('em') -> ems
pages <- ems[2] %>% html_text()
pages <- gsub(',','',pages)
install.packages("RSelenium")
install.packages("rvest")
library(RSelenium)
library(rvest)
library(xml2)
remDr <- remoteDriver(remoteServerAddr='localhost', port=4445L,browserName='chrome')
remDr
remDr$open
remDr$open()
remDr$navigate("https://nid.naver.com/nidlogin.login")
txt.id <- remDr$findElement(using='css selector', '#id')
txt.pw <- remDr$findElement(using='id', value="pw")
login_btn <- remDr$findElement(using='class', value='btn_global')
txt.id$setElementAttribute('value','skarnd93')
txt.pw$setElementAttribute('value','LOVEtkfkd12!')
login_btn$clickElement()
remDr$navigate('https://mail.naver.com/')
txt.id$setElementAttribute('value','skarnd93')
txt.pw$setElementAttribute('value','*****')
txt.id$setElementAttribute('value','skarnd93')
txt.pw$setElementAttribute('value','LOVEtkfkd12!')
txt.pw$setElementAttribute('value','LOVEtkfkd12!')
txt.id$setElementAttribute('value','skarnd93')
txt.id <- remDr$findElement(using='css selector', '#id')
txt.pw <- remDr$findElement(using='id', value="pw")
login_btn <- remDr$findElement(using='class', value='btn_global')
txt.id$setElementAttribute('value','skarnd93')
login_btn$clickElement()
txt.pw$setElementAttribute('value','LOVEtkfkd12!')
login_btn$clickElement()
remDr$navigate('https://mail.naver.com/')
mail_texts <- remDr$findElement(using='id',value='list_for_view')
mail_texts <- remDr$findElement(using='id',value='list_for_view')
# (using= 'css selector', 'subject)
mail_texts
mail_texts <- mail_texts$getElementText()
mail_texts
tmp <- str_split(mail_texts, '\n') %>% .[[1]]
tmp <- str_split(mail_texts, '\n') %>% .[[1]]
mail_texts <- mail_texts$getElementText()
# (using= 'css selector', 'subject)
mail_texts
mail_texts <- mail_texts$getElementText()
mail_texts
mail_textx <- mail_texts$getElementText()
mail_texts <- mail_texts$getElementText()
tmp <- str_split(mail_texts, '\n') %>% .[[1]]
subject <- c()
time <- c()
library(rvest)
library(dplyr)
library(stringr)
library(xlsx)
library(lubridate)
install.packages("RSelenium")
install.packages("rvest")
install.packages("rvest")
install.packages('xlsx')
library(rvest)
library(dplyr)
library(stringr)
library(xlsx)
library(lubridate)
install.packages('lubridate')
trim <- function(text){gsub("\\s+","",text)} # str_trim(text, c("both"))와 같음
@@ -36,6 +38,7 @@ lis <- NULL
score <- NULL
user_name <- NULL
date <- NULL
time <- NULL
up <- NULL
down <- NULL
movie_code <- NULL
for (url in page_url) {
date <-  c(date, lis %>% # 작성날짜 및 시간
html_node(".score_reple") %>%
html_nodes("em")  %>%
.[seq(2, length(lis)*3, by=3)] %>%
.[seq(2, length(lis)*3, by=3)] %>%
html_text() %>%
str_sub(., 1, 10))  # factor를 Date형식으로 변환 후 저장
str_replace_all(.,"\\.+","-"))
score <- c(score, lis %>% # 평점
html_node(".star_score") %>%
html_text() %>%
@@ -89,16 +92,18 @@ for (url in page_url) {
movie_name <- c(movie_name, rep(moviename, length(lis))) # 영화이름
}
naver_movie_reviews <- data.frame(영화명=movie_name,
영화코드=movie_code,
이름=user_name,
리뷰=reviews,
점수=score,
공감=up,
비공감=down,
날짜=as.Date(date,"%Y.%m.%d"),           # %Y.%m.%d으로 기존 날짜 형식의 형태를 알려줌
요일=weekdays(as.Date(date,"%Y.%m.%d"))) # weekdays 함수로 날짜에 맞는 요일 출력
library(xlsx)
날짜=str_sub(date,1,10),
시간=hour(date),
요일=wday(date, label = T)) # weekdays 함수로 날짜에 맞는 요일 출력
write.xlsx(naver_movie_reviews, file=paste0("네이버_영화_리뷰_",moviename,".xlsx"), row.names=F) # write.xlsx(변수, 파일명, ...)
str_replace_all(.,"\\.+","-")
str_replace_all(.,"\\.+","-"))
str_replace_all(.,"\\.+","-")
html_nodes("em")  %>%
date <-  c(date, lis %>% # 작성날짜 및 시간
html_node(".score_reple") %>%
html_nodes("em")  %>%
.[seq(2, length(lis)*3, by=3)] %>%
html_text() %>%
# factor를 Date형식으로 변환 후 저장
str_replace_all(.,"\\.+","-"))
for (url in page_url) {
date <-  c(date, lis %>% # 작성날짜 및 시간
html_node(".score_reple") %>%
html_nodes("em")  %>%
.[seq(2, length(lis)*3, by=3)] %>%
html_text() %>%
# factor를 Date형식으로 변환 후 저장
str_replace_all(.,"\\.+","-"))}
score <- c(score, lis %>% # 평점
html_node(".star_score") %>%
html_text() %>%
movie_name <- c(movie_name, rep(moviename, length(lis))) # 영화이름
for (url in page_url) {
movie_name <- c(movie_name, rep(moviename, length(lis))) # 영화이름
}
naver_movie_reviews <- data.frame(영화명=movie_name,
영화코드=movie_code,
이름=user_name,
리뷰=reviews,
점수=score,
공감=up,
비공감=down,
날짜=as.Date(date,"%Y.%m.%d"),           # %Y.%m.%d으로 기존 날짜 형식의 형태를 알려줌
요일=weekdays(as.Date(date,"%Y.%m.%d"))) # weekdays 함수로 날짜에 맞는 요일 출력
library(xlsx)
날짜=str_sub(date,1,10),
시간=hour(date),
요일=wday(date, label = T)) # weekdays 함수로 날짜에 맞는 요일 출력
score <- c(score, lis %>% # 평점
html_node(".star_score") %>%
html_text() %>%
for (url in page_url) {
movie_name <- c(movie_name, rep(moviename, length(lis))) # 영화이름
}
naver_movie_reviews <- data.frame(영화명=movie_name,
영화코드=movie_code,
이름=user_name,
리뷰=reviews,
점수=score,
공감=up,
비공감=down,
날짜=as.Date(date,"%Y.%m.%d"),           # %Y.%m.%d으로 기존 날짜 형식의 형태를 알려줌
요일=weekdays(as.Date(date,"%Y.%m.%d"))) # weekdays 함수로 날짜에 맞는 요일 출력
library(xlsx)
날짜=str_sub(date,1,10),
시간=hour(date),
요일=wday(date, label = T)) # weekdays 함수로 날짜에 맞는 요일 출력
score <- c(score, lis %>% # 평점
html_node(".star_score") %>%
html_text() %>%
for (url in page_url) {
movie_name <- c(movie_name, rep(moviename, length(lis))) # 영화이름
}
naver_movie_reviews <- data.frame(영화명=movie_name,
영화코드=movie_code,
이름=user_name,
리뷰=reviews,
점수=score,
공감=up,
비공감=down,
날짜=as.Date(date,"%Y.%m.%d"),           # %Y.%m.%d으로 기존 날짜 형식의 형태를 알려줌
요일=weekdays(as.Date(date,"%Y.%m.%d"))) # weekdays 함수로 날짜에 맞는 요일 출력
날짜=str_sub(date,1,10),
시간=hour(date),
요일=wday(date, label = T)) # weekdays 함수로 날짜에 맞는 요일 출력
write.xlsx(naver_movie_reviews, file=paste0("네이버_영화_리뷰_",moviename,".xlsx"), row.names=F) # write.xlsx(변수, 파일명, ...)
# NAVER 영화('알라딘') 네티즌 리뷰 크롤링
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
url_base <- 'https://movie.naver.com'
start_url <- '/movie/bi/mi/point.nhn?code=163788'
url <- paste0(url_base, start_url)
html <- read_html(url)
html %>%
html_node('iframe.ifr') %>%
html_attr('src') -> if_url
ifr_url <- paste0(url_base, if_url)
html2 <- read_html(ifr_url)
# 총 데이터 건수로부터 총 페이지수 구하기
html2 %>%
html_node('div.score_total') %>%
html_nodes('em') -> ems
pages <- ems[2] %>% html_text()
pages <- gsub(",", "", pages)
total_page <- ceiling(as.numeric(pages)/10)
# 페이지별 url 기본 구하기
html2 %>%
html_node('div.paging') %>%
html_node('a') %>%
html_attr('href') -> tmp
page_url_base <- str_sub(tmp, 1, -2)
# 평점 데이터를 저장할 데이터프레임 초기화
df_points <- data.frame(score=c(), review=c(), writer=c(), time=c())
for (i in 1:total_page) {
if (i %% 100 == 0)
print(i)
page_url <- paste0(url_base, page_url_base, i)
html <- read_html(page_url)
html %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
score <- c()
review <- c()
writer <- c()
time <- c()
for (li in lis) {
score <- c(score, html_node(li, '.star_score') %>% html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> tmp
idx <- str_locate(tmp, "\r")
rev <- str_sub(tmp, 1, idx[1]-1)
#print(rev)
review <- c(review, rev)
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
writer <- c(writer, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
time <- c(time, str_sub(tmp, 1, idx[1]-1))
}
points <- data.frame(score=score, review=review, writer=writer, time=time)
df_points <- rbind.data.frame(df_points, points)
}
write.xlsx(df_points, file="D:/Workspace/R_Project/01_Crawling/cine.xlsx",
sheetName="네티즌평점",
col.names=TRUE, row.names=FALSE, append=FALSE)
write.xlsx(df_points, file="E:/190527남궁하영/크롤링",
sheetName="네티즌평점",
col.names=TRUE, row.names=FALSE, append=FALSE)
df <-read_excel("instagram.xlsx",sheet = "Sheet1", encoding = utf-16);df
setwd('C:/Users/709-000/Desktop/wedcrawling/인스타 크롤 관련')
df <-read_excel("instagram.xlsx",sheet = "Sheet1", encoding = 'utf-16');df
df <-read_excel("instagram.xlsx",sheet = "Sheet1");df
library(stringr)
library(dplyr)
library(rJava)
library(xlsx)
library(RJavaTools)
library(readxl)
setwd('C:/Users/709-000/Desktop/wedcrawling/인스타 크롤 관련')
df <-read_excel("instagram.xlsx",sheet = "Sheet1");df
, encoding = 'utf-16'
df <-read_excel("instagram.xlsx",sheet = "Sheet1", encoding = 'utf-16');df
df <-read_excel("instagram.xlsx",sheet = "Sheet1", Encoding = 'utf-16');df
df <-read_excel("instagram.xlsx",sheet = "Sheet1", fileEncoding() = 'utf-16');df
df <-read_excel("instagram.xlsx",sheet = "Sheet1", fileEncoding= 'utf-16');df
df <-read_excel("instagram.xlsx",sheet = "Sheet1", fileEncoding('utf-16'));df
df <-read_excel("instagram.xlsx",sheet = "Sheet1", fileEncoding = 'utf-16');df
df <-read_excel("instagram.xlsx",sheet = "Sheet1", encoding = 'utf-16');df
df <-read_excel("instagram.xlsx",sheet = "Sheet1", encoding = 'cp949');df
df <-read_excel("instagram.xlsx",sheet = "Sheet1");df
df <- read.csv('인스타그램.csv',encoding='utf-16')
df <- read.csv('인스타그램.csv',encoding='utf-16')
df <- read.table('인스타그램.csv',encoding='utf-16')
df <- read.table('인스타그램.csv',encoding='utf-16')
df <- read.table('인스타그램.csv',fileEncoding='utf-16')
df <- read.table('tag.csv',fileEncoding='utf-16',readTableHeader=T)
df <- read.table('tag.csv',fileEncoding='utf-16')
df <- read.table('tag.csv',fileEncoding='utf-16',stringsAsFactors=FALSE, header=FALSE, nrows=10)
# df <-read_excel("instagram.xlsx",sheet = "Sheet1");df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
df <- read.table('tag.csv',fileEncoding='utf-16',stringsAsFactors=FALSE, header=FALSE)
# df <-read_excel("instagram.xlsx",sheet = "Sheet1");df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
df <- read.table('tag.csv',fileEncoding='utf-16',stringsAsFactors=FALSE, header=FALSE,sep=",")
# df <-read_excel("instagram.xlsx",sheet = "Sheet1");df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
df <- read.table('tag.csv',fileEncoding='utf-16',stringsAsFactors=FALSE, header=FALSE,sep=",")
# df <-read_excel("instagram.xlsx",sheet = "Sheet1");df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
df <- read.table('tag.csv',fileEncoding='utf-32',stringsAsFactors=FALSE, header=FALSE,sep=",")
# df <-read_excel("instagram.xlsx",sheet = "Sheet1");df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
df <- read.table('tag.csv',fileEncoding='utf-32')
df <-read_excel("instagram.xlsx",sheet = "Sheet1",fileEncoding='utf-32');df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
df <-read_excel("instagram.xlsx",sheet = "Sheet1",encoding='utf-32');df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
df <- read.table('tag.csv',fileEncoding='utf-32')
df <-read_excel("instagram.xlsx",sheet = "Sheet1");df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
hs <- select(df, data2)
hs <- unlist(hs);hs
s <- strsplit(hs, "#")
s <- data.frame(s)
length(s$data21)
length(s$data2)
str(s)
tolower(s) # 소문자로 만들기
View(s)
s<- tolower(s) # 소문자로 만들기
View(s)
s<- str_trim(s)# 공백 없애기
s <- unlist(s)
save(s,file = 'gello', Encoding='utf-32')
write.table(s,file ='df.txt',fileEncoding='utf-32')
library(stringr)
library(dplyr)
library(rJava)
library(xlsx)
library(RJavaTools)
library(readxl)
getwd()
setwd('C:/Users/709-000/Desktop/wedcrawling/인스타 크롤 관련')
df <-read_excel("instagram.xlsx",sheet = "Sheet1");df# 이거는 잘나오는데 마지막 인코딩에서 ㅄ됨,,
hs <- select(df, data2)
hs <- unlist(hs);hs
s <- strsplit(hs, "#")
s <- data.frame(s)
str(s)
s
s<- tolower(s) # 소문자로 만들기
s<- str_trim(s)# 공백 없애기
getOption("encoding")
options(encoding=utf-32)
options(encoding='utf-32')
write.table(s,file ='df.txt',fileEncoding='utf-32')
write.csv(s, file = 'my_data.txt')
s<- str_trim(s)# 공백 없애기
write.table(s,file ='df.txt',fileEncoding='utf-32')
write.table(s,file ='df.txt',fileEncoding='utf-32',sep='')
write.table(s,file ='df.txt',fileEncoding='utf-16',sep='')
write.table(s,file ='df.txt',fileEncoding='utf-32',sep='')
df <- read.table('tag.csv',fileEncoding='utf-32')
df <- read.table('tag.csv')
df <- read.table('tag.txt')
df <- read.table('df.txt')
